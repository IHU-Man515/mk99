<!DOCTYPE html><html lang="en"><head><meta charset="utf-8" /><meta name="author" content="== !" /><title>Machine learning, data science and artificial intelligence</title><meta content="yes" name="apple-mobile-web-app-capable" /><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style" /><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui" name="viewport" /><link href="reveal.js-3.6.0/css/reveal.css" rel="stylesheet" /><link rel="stylesheet" href="reveal.js-3.6.0/css/theme/white.css" id="theme" /><style>/* Stylesheet for CodeRay to match GitHub theme | MIT License | http://foundation.zurb.com */
pre.CodeRay{background:#f7f7f8}
.CodeRay .line-numbers{border-right:1px solid currentColor;opacity:.35;padding:0 .5em 0 0}
.CodeRay span.line-numbers{display:inline-block;margin-right:.75em}
.CodeRay .line-numbers strong{color:#000}
table.CodeRay{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.CodeRay td{vertical-align:top;line-height:inherit}
table.CodeRay td.line-numbers{text-align:right}
table.CodeRay td.code{padding:0 0 0 .75em}
.CodeRay .debug{color:#fff !important;background:#000080 !important}
.CodeRay .annotation{color:#007}
.CodeRay .attribute-name{color:#000080}
.CodeRay .attribute-value{color:#700}
.CodeRay .binary{color:#509}
.CodeRay .comment{color:#998;font-style:italic}
.CodeRay .char{color:#04d}
.CodeRay .char .content{color:#04d}
.CodeRay .char .delimiter{color:#039}
.CodeRay .class{color:#458;font-weight:bold}
.CodeRay .complex{color:#a08}
.CodeRay .constant,.CodeRay .predefined-constant{color:#008080}
.CodeRay .color{color:#099}
.CodeRay .class-variable{color:#369}
.CodeRay .decorator{color:#b0b}
.CodeRay .definition{color:#099}
.CodeRay .delimiter{color:#000}
.CodeRay .doc{color:#970}
.CodeRay .doctype{color:#34b}
.CodeRay .doc-string{color:#d42}
.CodeRay .escape{color:#666}
.CodeRay .entity{color:#800}
.CodeRay .error{color:#808}
.CodeRay .exception{color:inherit}
.CodeRay .filename{color:#099}
.CodeRay .function{color:#900;font-weight:bold}
.CodeRay .global-variable{color:#008080}
.CodeRay .hex{color:#058}
.CodeRay .integer,.CodeRay .float{color:#099}
.CodeRay .include{color:#555}
.CodeRay .inline{color:#000}
.CodeRay .inline .inline{background:#ccc}
.CodeRay .inline .inline .inline{background:#bbb}
.CodeRay .inline .inline-delimiter{color:#d14}
.CodeRay .inline-delimiter{color:#d14}
.CodeRay .important{color:#555;font-weight:bold}
.CodeRay .interpreted{color:#b2b}
.CodeRay .instance-variable{color:#008080}
.CodeRay .label{color:#970}
.CodeRay .local-variable{color:#963}
.CodeRay .octal{color:#40e}
.CodeRay .predefined{color:#369}
.CodeRay .preprocessor{color:#579}
.CodeRay .pseudo-class{color:#555}
.CodeRay .directive{font-weight:bold}
.CodeRay .type{font-weight:bold}
.CodeRay .predefined-type{color:inherit}
.CodeRay .reserved,.CodeRay .keyword {color:#000;font-weight:bold}
.CodeRay .key{color:#808}
.CodeRay .key .delimiter{color:#606}
.CodeRay .key .char{color:#80f}
.CodeRay .value{color:#088}
.CodeRay .regexp .delimiter{color:#808}
.CodeRay .regexp .content{color:#808}
.CodeRay .regexp .modifier{color:#808}
.CodeRay .regexp .char{color:#d14}
.CodeRay .regexp .function{color:#404;font-weight:bold}
.CodeRay .string{color:#d20}
.CodeRay .string .string .string{background:#ffd0d0}
.CodeRay .string .content{color:#d14}
.CodeRay .string .char{color:#d14}
.CodeRay .string .delimiter{color:#d14}
.CodeRay .shell{color:#d14}
.CodeRay .shell .delimiter{color:#d14}
.CodeRay .symbol{color:#990073}
.CodeRay .symbol .content{color:#a60}
.CodeRay .symbol .delimiter{color:#630}
.CodeRay .tag{color:#008080}
.CodeRay .tag-special{color:#d70}
.CodeRay .variable{color:#036}
.CodeRay .insert{background:#afa}
.CodeRay .delete{background:#faa}
.CodeRay .change{color:#aaf;background:#007}
.CodeRay .head{color:#f8f;background:#505}
.CodeRay .insert .insert{color:#080}
.CodeRay .delete .delete{color:#800}
.CodeRay .change .change{color:#66f}
.CodeRay .head .head{color:#f4f}</style><link href="reveal.js-3.6.0/lib/css/zenburn.css" rel="stylesheet" /><script>document.write( '<link rel="stylesheet" href="reveal.js-3.6.0/css/print/' + ( window.location.search.match( /print-pdf/gi ) ? 'pdf' : 'paper' ) + '.css" type="text/css" media="print">' );</script></head><body><div class="reveal"><div class="slides"><section class="title"><h1>Machine learning, data science and artificial intelligence</h1><div class="preamble"><div class="paragraph"><p>2019-05-09</p></div></div><p class="author"><small>== !</small></p></section>
<section><div class="imageblock stretch" style="text-align: center"><img src="../images/EMLyon_logo_corp.png" alt="EMLyon logo corp" width="242" /></div></section>
<section><div class="paragraph"><p>first edition: 2017-11-01</p></div></section>
<section id="_1_explaining_machine_learning_in_simple_terms"><h2>1. Explaining machine learning in simple terms</h2></section>
<section></section>
<section><h3>a. A comparison with classic statistics</h3></section>
<section><div class="paragraph"><p></p></div></section>
<section><div class="paragraph"><p>We will <a href="https://stats.stackexchange.com/questions/6/the-two-cultures-statistics-vs-machine-learning">compare machine learning to a classic example from statistics</a>: computing a regression line to identify a trend in a scatter plot.</p></div></section>
<section><div class="paragraph"><p>To illustrate, we take some data about marketing budgets and sales figures in the corresponding period:</p></div></section>
<section><iframe width="600" height="371" seamless frameborder="0" scrolling="no" src="https://docs.google.com/spreadsheets/d/e/2PACX-1vS8dKfwxvgz3ALH8Y1FzxWk9lZtiVBlQdZYUrKJqRXNqBFRjKIP3LUvv29QSIBbGx2-ray5nK8cALMH/pubchart?oid=1075418595&format=interactive"></iframe></section>
<section><div class="paragraph"><p>"Regular statistics" enables, among other things:</p></div></section>
<section><div class="olist arabic"><ol class="arabic"><li><p>to find the numerical relation between the 2 series, based on a pre-established formal model (eg, <a href="https://en.wikipedia.org/wiki/Ordinary_least_squares">ordinary least squares</a>).</p></li></ol></div>
<div class="paragraph"><p>&#8594; we see that sales are correlated with marketing spendings. It is likely that more marketing spending causes more sales.</p></div></section>
<section><div class="olist arabic"><ol class="arabic" start="2"><li><p>to predict, based on this model:</p></li></ol></div>
<div class="paragraph"><p>&#8594; by tracing the line further (using the formal model), we can predict the effect of more marketing spending</p></div></section>
<section><div class="paragraph"><p>"Regular statistics" is advanced by scientists who:</p></div>
<div class="olist arabic"><ol class="arabic"><li><p>are highly skilled in mathematics</p></li></ol></div></section>
<section></section>
<section><div class="paragraph"><p>&#8594; their goal is to find the exact mathematical expression defining the situation at hand, under rigorous conditions</p></div></section>
<section><div class="paragraph"><p>&#8594; a key approach is <strong>inference</strong>: by defining a <strong>sample of the data</strong> of just the correct size, we can reach conclusions which are valid for the entire dataset.</p></div></section>
<section><div class="olist arabic"><ol class="arabic" start="2"><li><p>have no training in computer science / software engineering</p></li></ol></div>
<div class="paragraph"><p>&#8594; they neglect how hard it can be to to run their models on computers, in terms of calculations to perform.</p></div>
<div class="paragraph"><p>&#8594; since they focus on <strong>sampling</strong> the data, they are not concerned with handling entire datasets with related IT issues.</p></div></section>
<section><div class="paragraph"><p><strong>Machine learning</strong> does similar things to statistics, but in a slightly different way:</p></div>
<div class="ulist"><ul><li><p>there is an emphasis on getting the prediction right, not caring for identifying the underlying mathematical model</p></li><li><p>the prediction needs to be achievable in the time available, with the computing resources available</p></li><li><p>the data of interest is in a format / in a volume which is not commonly handled by regular statistics package (eg: images, observations with hundreds of features)</p></li></ul></div></section>
<section><div class="paragraph"><p>Machine learning is advanced by scientists who are typically:</p></div></section>
<section><div class="olist arabic"><ol class="arabic" start="1"><li><p>highly skilled in statistics (the "classic" statistics we have seen above)</p></li></ol></div></section>
<section><div class="olist arabic"><ol class="arabic" start="2"><li><p>with a training or experience in computer science, familiar with working with unstructured data / big data</p></li></ol></div></section>
<section><div class="olist arabic"><ol class="arabic" start="3"><li><p>working in environments (industry, military, &#8230;&#8203;) where the operational aspects of the problem are key determinants (unstructured data, limits on computing resources)</p></li></ol></div></section>
<section><div class="paragraph"><p>Machine learning puts a premium on techniques which are "computationally adequate":</p></div></section>
<section><div class="ulist"><ul><li><p>which need the minimum / the simplest algebraic operations to run: the best technique is worthless if it&#8217;s too long or expensive to compute.</p></li><li><p>which can be run in such a way that multiple computers work in parallel (simultaneously) to solve it.</p></li></ul></div></section>
<section><div class="paragraph"><p>(footnote: so machine learning, in my opinion, shares the spirit of "getting things done" as was <a href="https://en.wikipedia.org/wiki/Operations_research#Second_World_War">operations research in  the early days</a>)</p></div></section>
<section><div class="paragraph"><p>The pursuit of improved models in traditional statistics is not immune to the notion of computational efficiency - it does count as a desirable property - but in machine learning this is largely a pre-requisite.</p></div></section>
<section><h3>b. An illustration: the case of the GPU</h3></section>
<section></section>
<section><div class="paragraph"><p>A key illustration of the difference between statistics and machine learning can be provided with the use of <strong>graphic cards</strong>.</p></div></section>
<section><div class="paragraph"><p>Graphic cards (or GPUs: graphics processing units) are these electronic boards full of chips found inside a computer, which are used for the display of images and videos on computer screens:</p></div></section>
<section><div class="imageblock stretch" style="text-align: center"><img src="../images/gpu.jpg" alt="gpu" width="300" /></div><div class="title">Figure 1. A graphic card sold by NVidia - a leading manufacturer</div></section>
<section></section>
<section><div class="paragraph"><p>In the 1990s, video gaming developed a lot from arcades to desktop computers. Game developers created computer games showing more and more complex scenes and animations. (see <a href="https://youtu.be/3UTdxI2IEp0">an evolution of graphics</a>, and <a href="https://www.youtube.com/watch?v=Rywkv7PCYDM">advanced graphics games in 2017</a>).</p></div></section>
<section><div class="paragraph"><p>These video games need powerful video cards (aka <a href="https://en.wikipedia.org/wiki/Graphics_processing_unit">GPUs</a>) to render complex scenes in full details - with calculations on light effects and animations <strong>made in real time</strong>.</p></div></section>
<section><div class="paragraph"><p>This pushed for the development of ever more powerful <strong>GPUs</strong>.
Their characteristics is that they can compute simple operations to change pixel colors, <strong>for each of the millions of pixels of the screen in parallel</strong>, so that the next frame of the picture can be rendered in milliseconds.</p></div></section>
<section><div class="paragraph"><p>Millions of simple operations run in parallel for the price of a GPU (a couple of hundreds of dollars), not the price of dozens of computers running in parallel (can be dozens of thousands of dollars)?
This is interesting for computations on big data!</p></div></section>
<section><div class="paragraph"><p>If a statistical problem for prediction can be broken down into simple operations which can be run on a GPU, then a large dataset can be analyzed in seconds or minutes on a laptop, instead of  cluster of computers.</p></div></section>
<section><div class="paragraph"><p>To illustrate the difference in speed between a mathematical operation run without / with a <strong>GPU</strong>:</p></div></section>
<section><div class="videoblock stretch"><iframe width="500" height="400" src="https://www.youtube.com/embed/-P28LKWTzrI?rel=0" frameborder="0" allowfullscreen=""></iframe></div></section>
<section></section>
<section><div class="paragraph"><p>The issue is: to use a GPU for calculations, you need to conceptualize the problem at hand as one that can be:</p></div>
<div class="ulist"><ul><li><p>broken into a very large series</p></li><li><p>of very simple operations (basically, sums or multiplications, nothing complex like square roots or polynomials)</p></li><li><p>which can run independently from each other.</p></li></ul></div></section>
<section><div class="paragraph"><p>Machine learning typically pays attention to this dimension of the problem right from the design phase of models and techniques, where statistics would typically not consider the issue, or only downstream: not at the design phase but at the implementation phase.</p></div></section>
<section><div class="paragraph"><p>Now that we have seen how statistics and machine learning differ in their approach, we still need to understand how does machine learning get good results, if it does not rely on modelling / sampling the data like statistics does?</p></div>
<div class="paragraph"><p>Machine learning can be categorized in 3 families of tricks:</p></div></section>
<section id="_2_three_families_of_machine_learning"><h2>2. Three families of machine learning</h2></section>
<section><h3>a. The unsupervised learning approach</h3></section>
<section><div class="paragraph"><p><strong>Unsupervised learning</strong> designates the methods which take a fresh dataset and find interesting patterns in it, <strong>without inferring from previous, similar datasets</strong>.</p></div>
<div class="paragraph"><p>How does supervised learning work? Let&#8217;s take an example. In a wedding reception, how to sit people with similar interests at the same tables?</p></div></section>
<section><div class="paragraph"><p>The set up:</p></div>
<div class="ulist"><ul><li><p>a list of 100 guests, and 3 tastes you know they have for each of them</p></li><li><p>10 tables with 10 sits each.</p></li></ul></div></section>
<section><div class="ulist"><ul><li><p>a measure of similarity between 2 guests: 2 guests have similarity of 0% if they share 0 tastes, 33% if they share 1 taste, 66% with 2 tastes in common, 100% with three matching interests.</p></li></ul></div></section>
<section><div class="ulist"><ul><li><p>a measure of similarity at the level of a table: the sum of similarities between all pairs of guests at the table (45 pairs possible for a table of 10).</p></li></ul></div></section>
<section><div class="paragraph"><p>A possible solution using an unsupervised approach:</p></div></section>
<section><div class="ulist"><ul><li><p>on a computer, assign randomly the 100 guests to the 10 tables.</p></li></ul></div></section>
<section><div class="ulist"><ul><li><p>for each table:</p><div class="ulist"><ul><li><p>measure the degree of similarity of tastes for the table</p></li><li><p>exchange the sit of 1 person at this table, with the sit of a person at a different table.</p></li><li><p>measure again the degree of similarity for the table: if it improves, keep the new sits, if not, revert to before the exchange</p></li></ul></div></li></ul></div>
<div class="paragraph"><p>And repeat for all tables, many times, until no exchange of sits improves the similarity. When this stage is achieved, we say the model has "<strong>converged</strong>".</p></div></section>
<section><div class="paragraph"><p>This approach makes it possible to identify groups of people who have common points.
It is obviously very useful to organize the world around us in business, from a segmentation of customers or prospects, to a classification of products in categories for evaluation or portfolio management purposes.</p></div></section>
<section><div class="paragraph"><p>There is a very large field of scientific research devoted to designing better clustering techniques suiting a variety of situations.
One of the most popular of these techniques remains the"k-means", and was invented in the 1950s:</p></div></section>
<section><div class="imageblock stretch" style="text-align: center"><img src="../images/kmeans.jpg" alt="kmeans" width="300" /></div><div class="title">Figure 2. k-means clustering - an unsupervised learning approach</div></section>
<section><h3>b. The <strong>supervised</strong> learning approach</h3></section>
<section><div class="paragraph"><p><strong>Supervised learning</strong> is the approach consisting in calibrating a model based on the history of past experiences in order to guess / predict a new occurrence of the same experience.</p></div>
<div class="paragraph"><p>Take 50,000 or more observations, or data points, like:</p></div>
<div class="ulist"><ul><li><p>an image of a cat, with the caption "cat"</p></li><li><p>an image of a dog, with the caption "dog"</p></li><li><p>another image of a cat, with the caption "cat"</p></li></ul></div>
<div class="paragraph"><p>etc&#8230;&#8203;.</p></div></section>
<section><div class="ulist"><ul><li><p>you need 50,000 observations of this kind, or more! It is called the <strong>training set</strong>.</p></li><li><p>this is also called a <strong>labelled dataset</strong>, meaning that we have a label describing each of the observation.</p></li></ul></div></section>
<section><div class="admonitionblock tip"><table><tr><td class="icon"><div class="title"></div></td><td class="content"><div class="paragraph"><p>In a trained dataset, where do the labels come from?</p></div>
<div class="ulist"><ul><li><p>they can be simply be provided by users of a service. For instance, pics on Instagram captioned by hashtags are exactly that: a picture with a label. The labelling is done by the users of Instagram posting the pictures and writing the hashtags below it. Instagram is a free service but the training sets it creates are of great value to the company (Instagram is owned by Facebook).</p></li><li><p>they can be produced by human workers. In practice, humans are paid a few cents per picture which they have to label (is it a cat? is it a dog? etc.). A large industry and job market is developing to perform a variety of tasks of this kind. There is a growing workforce providing their digital labor to companies in need of <strong>data labeling</strong> or <strong>data curation</strong>. See the work of <a href="http://www.casilli.fr/about/">Antonio Casilli</a> for further reference.</p></li></ul></div></td></tr></table></div></section>
<section><div class="paragraph"><p>The task is: if we give our computer a new image of a cat without a label, will it be able to guess the label "cat"?</p></div></section>
<section><div class="paragraph"><p>The method:</p></div>
<div class="ulist"><ul><li><p>take a list of random coefficients (in practice, the list is a vector, or a matrix).</p></li></ul></div></section>
<section><div class="ulist"><ul><li><p>for each of the 50,000 pictures of dogs and cats:</p><div class="ulist"><ul><li><p>apply the coefficients to the picture at hand (let&#8217;s say we have a dog here)</p></li><li><p>If the result is "dog", do nothing, it works!</p></li><li><p>If the result is "cat", change slightly the coefficients.</p></li><li><p>move to the next picture</p></li></ul></div></li></ul></div></section>
<section><div class="ulist"><ul><li><p>After looping through 50,000 pictures the parameters have hopefully adjusted and fine tuned. This was the <strong>training of the model</strong>.</p></li></ul></div></section>
<section><div class="paragraph"><p>Now, when you get new pictures (the <strong>fresh set</strong>), applying the trained model should output a correct prediction ("cat" or "dog").</p></div></section>
<section><div class="paragraph"><p>Supervised learning is currently the most popular family of machine learning and obtains excellent results especially in image recognition, even though some cases remain hard to crack:</p></div></section>
<section><div class="imageblock stretch" style="text-align: center"><img src="../images/muffin.jpg" alt="muffin" width="400" /></div><div class="title">Figure 3. A hard test case for supervised learning</div></section>
<section></section>
<section><div class="paragraph"><p>It is called <strong>supervised</strong> learning because the learning is very much constrained / supervised by the intensive training performed:</p></div>
<div class="paragraph"><p>&#8594; there is limited or no "unsupervised discovery" of novelty.</p></div></section>
<section><div class="videoblock stretch"><iframe width="500" height="400" src="https://www.youtube.com/embed/4HCE1P-m1l8?rel=0" frameborder="0" allowfullscreen=""></iframe></div></section>
<section></section>
<section><div class="paragraph"><p>Important take away on the supervised approach:</p></div>
<div class="ulist"><ul><li><p><strong>collecting <em>large</em> datasets for training is key</strong>. Without these data, no supervised learning.</p></li><li><p>supervised learning is not good at analyzing situations entirely different from what is in the training set.</p></li></ul></div></section>
<section><h3>c. The <strong>reinforcement</strong> learning approach</h3></section>
<section></section>
<section><div class="paragraph"><p>To understand reinforcement learning in an intuitive sense, we can think of how animals can learn quickly by <strong>ignoring</strong> undesirable behavior and rewarding desirable behavior.</p></div>
<div class="paragraph"><p>This is easy and takes just seconds. The following video shows B.F. Skinner, main figure in psychology in the 1950s-1970s:</p></div></section>
<section><div class="videoblock stretch"><iframe width="500" height="400" src="https://www.youtube.com/embed/TtfQlkGwE2U?rel=0" frameborder="0" allowfullscreen=""></iframe></div></section>
<section></section>
<section><div class="paragraph"><p>Footnote: how does this apply to learning in humans? On the topic of learning and decision making, I warmly recommend <a href="https://global.oup.com/academic/product/foundations-of-neuroeconomic-analysis-9780199744251">Foundations of Neuroeconomic Analysis by Paul Glimcher</a>, professor of neuroscience, psychology and economics at NYU:</p></div></section>
<section><div class="admonitionblock tip"><table><tr><td class="icon"><div class="title"></div></td><td class="content"><div class="paragraph"><p>this is a very hard book to read as it covers three disciplines in depth. The biological mechanisms of decision making it describes can be inspiring to design new computational approaches.</p></div></td></tr></table></div></section>
<section><div class="imageblock stretch" style="text-align: center"><img src="../images/glimcher.jpg" alt="glimcher" width="250" /></div><div class="title">Figure 4. Foundations of Neuroeconomics by Paul Glimcher - 2010</div></section>
<section></section>
<section><div class="paragraph"><p>Besides pigeons, reinforcement learning can be applied to any kind of "expert agents".</p></div>
<div class="paragraph"><p>Take the case of a video game like Super Mario Bros:</p></div></section>
<section><div class="imageblock stretch" style="text-align: center"><img src="../images/mario.jpg" alt="mario" height="100%" /></div><div class="title">Figure 5. Mario Bros, a popular video game</div></section>
<section></section>
<section><div class="paragraph"><p>Structure of the game / the task:</p></div>
<div class="ulist"><ul><li><p>Goal of the task: Mario should collect gold coins and complete the game by reaching the far right of the screen.</p></li><li><p>Negative outcome to be avoided: Mario getting killed by enemies or falling in holes.</p></li></ul></div></section>
<section><div class="ulist"><ul><li><p>Starting point: Mario Bros is standing at the beginning of the game, doing nothing.</p></li><li><p>Possible actions: move right, jump, stand &amp; do nothing, shoot ahead.</p></li></ul></div></section>
<section><div class="paragraph"><p>Reinforcement learning works by:</p></div>
<div class="olist arabic"><ol class="arabic"><li><p>Making Mario do a new random action ("try something"), for example: "move right"</p></li><li><p>The game ends (Mario moved right, gets hit by a enemy)</p></li></ol></div></section>
<section><div class="olist arabic"><ol class="arabic" start="3"><li><p>This result is stored somewhere:</p><div class="ulist"><ul><li><p>move right = good (progress towards the goal of the game)</p></li><li><p>walking close to an enemy and getting hit by it = bad</p></li></ul></div></li></ol></div></section>
<section><div class="olist arabic"><ol class="arabic" start="4"><li><p>Game starts over (back to step 1) with a a combination of</p><div class="ulist"><ul><li><p>continue doing actions recorded as positive</p></li><li><p>try something new (jump, shoot?) when close to a situation associated with a negative outcome</p></li></ul></div></li></ol></div></section>
<section><div class="paragraph"><p>After looping from 1. to 4. thousands of times, Mario completes the game, without any human player:</p></div></section>
<section><div class="videoblock stretch"><iframe width="500" height="400" src="https://www.youtube.com/embed/qv6UVOQ0F44?rel=0" frameborder="0" allowfullscreen=""></iframe></div></section>
<section></section>
<section><div class="paragraph"><p>Reinforcement learning is perceived as corresponding to an important side of human learning / human intelligence (goal oriented, "trial and error").</p></div></section>
<section><h3>d. When is machine learning useful?</h3></section>
<section></section>
<section><div class="paragraph"><p>Using machine learning can be a waste of resource, when well known statistics could be easily applied.</p></div></section>
<section><div class="paragraph"><p>Hints that "classic" statistical modeling (maybe as simple as a linear regression) should be enough:</p></div></section>
<section><div class="ulist"><ul><li><p>The dataset is not large (below 50k observations), supervised learning is not going to work</p></li><li><p>The data is perfectly structured (tabular data)</p></li><li><p>The data points have few features</p></li></ul></div></section>
<section><div class="paragraph"><p>Cases when "classic" statistics modeling is <strong>necessary</strong>:</p></div>
<div class="ulist"><ul><li><p>The question is about the relative contribution of independent variables to the determination of an outcome</p></li></ul></div></section>
<section id="_3_machine_learning_and_data_science"><h2>3. Machine Learning and Data Science</h2></section>
<section></section>
<section><div class="paragraph"><p>Machine learning is a step in the longer chain of steps of data science.</p></div></section>
<section><div class="paragraph"><p>The process was formalized as <a href="https://en.wikipedia.org/wiki/Data_mining#Process">kdd</a>: "Knowledge Discovery in Databases":</p></div></section>
<section><div class="imageblock stretch" style="text-align: center"><img src="../images/kdd.png" alt="kdd" width="500" /></div><div class="title">Figure 6. KDD - knowledge discovery in databases</div></section>
<section></section>
<section><div class="paragraph"><p>More recent representations of the steps in data processing have been suggested, making room for the role of data visualization:</p></div>
<div class="paragraph"><p>&#8594; see <a href="https://image.slidesharecdn.com/datavisualizationforbusiness-141017095602-conversion-gate01/95/data-visualization-for-business-13-638.jpg?cb=1414060400">the information design process by Ben Fry</a> and this <a href="http://blogger.ghostweather.com/2013/11/data-vis-consulting-advice-for-newbies.html">data visualization workflow by Moritz Stefaner</a>:</p></div></section>
<section><div class="imageblock stretch" style="text-align: center"><img src="../images/stefaner.png" alt="stefaner" width="500" /></div><div class="title">Figure 7. data visualization workflow by Moritz Stefaner</div></section>
<section></section>
<section><div class="paragraph"><p>Machine learning is one of the techniques (along with traditional statistics) that intervenes at the step of "Data mining".</p></div></section>
<section><div class="paragraph"><p>What makes data scientists important is that the steps of this kdd are highly interdependent.</p></div></section>
<section><div class="paragraph"><p>You need individuals or teams who are not just versed in data mining:</p></div>
<div class="paragraph"><p>&#8594; because the shape of the data at the collection stage has a huge influence on the kind of techniques, and the kind of software, that can be used to discover knowledge.</p></div></section>
<section><div class="paragraph"><p>The skills of a data scientist are often represented as the meeting of three separate domains:</p></div></section>
<section><div class="imageblock stretch" style="text-align: center"><img src="../images/conway.png" alt="conway" height="100%" /></div><div class="title">Figure 8. The Venn diagram of data science by Drew Conway</div></section>
<section></section>
<section id="_4_artificial_intelligence"><h2>4. Artificial intelligence</h2></section>
<section></section>
<section><h3>a. Weak vs Strong AI</h3></section>
<section></section>
<section><div class="paragraph"><p><strong>Weak AI</strong> designates computer programs able to outperform humans at complex tasks with a narrow focus (playing chess)</p></div></section>
<section><div class="paragraph"><p>Weak AI is typically the result of applying expert systems or machine learning techniques seen above.</p></div></section>
<section><div class="paragraph"><p><strong>Strong AI</strong> is an intelligence that would be general in scope, able to set its own goal, and conscious of itself.
Nothing is close to that yet.</p></div></section>
<section><div class="paragraph"><p>So AI is a synonymous with weak AI at the moment.</p></div></section>
<section><h3>b. Two videos to understand AI further</h3></section>
<section></section>
<section><div class="paragraph"><p>Laurent Alexandre on the social and economic stakes of <strong>AI</strong> (in French):</p></div></section>
<section><div class="videoblock stretch"><iframe width="500" height="400" src="https://www.youtube.com/embed/rJowm24piM4?rel=0" frameborder="0" allowfullscreen=""></iframe></div></section>
<section></section>
<section><div class="paragraph"><p>John Launchbury, Director of DARPA&#8217;s Information Innovation Office (I2O) in 2017:</p></div></section>
<section><div class="videoblock stretch"><iframe width="500" height="400" src="https://www.youtube.com/embed/-O01G3tSYpU?rel=0" frameborder="0" allowfullscreen=""></iframe></div></section>
<section></section>
<section id="_the_end"><h2>The end</h2></section>
<section></section>
<section><div class="paragraph"><p>Find references for this lesson, and other lessons, <a href="https://seinecle.github.io/mk99/">here</a>.</p></div>
<div class="paragraph"><p><span class="image right"><img src="../images/round_portrait_mini_150.png" alt="round portrait mini 150" /></span>
This course is made by Clement Levallois.</p></div>
<div class="paragraph"><p>Discover my other courses in data / tech for business: <a href="https://www.clementlevallois.net" class="bare">https://www.clementlevallois.net</a></p></div>
<div class="paragraph"><p>Or get in touch via Twitter: <a href="https://www.twitter.com/seinecle">@seinecle</a>
    <!-- Start of StatCounter Code for Default Guide -->
    <script type="text/javascript">
        var sc_project = 11411204;
        var sc_invisible = 1;
        var sc_security = "11411204";
        var scJsHost = (("https:" == document.location.protocol) ?
            "https://secure." : "http://www.");
        document.write("<sc" + "ript type='text/javascript' src='" +
            scJsHost +
            "statcounter.com/counter/counter.js'></" + "script>");
    </script>
    <noscript><div class="statcounter"><a title="site stats"
    href="http://statcounter.com/" target="_blank"><img
    class="statcounter"
    src="//c.statcounter.com/11411204/0/11411204/1/" alt="site
    stats"></a></div></noscript>
    <!-- End of StatCounter Code for Default Guide --></p></div></section></div></div><script src="reveal.js-3.6.0/lib/js/head.min.js"></script><script src="reveal.js-3.6.0/js/reveal.js"></script><script>// See https://github.com/hakimel/reveal.js#configuration for a full list of configuration options
Reveal.initialize({
  // Display controls in the bottom right corner
  controls: true,
  // Display a presentation progress bar
  progress: true,
  // Display the page number of the current slide
  slideNumber: false,
  // Push each slide change to the browser history
  history: false,
  // Enable keyboard shortcuts for navigation
  keyboard: true,
  // Enable the slide overview mode
  overview: true,
  // Vertical centering of slides
  center: true,
  // Enables touch navigation on devices with touch input
  touch: true,
  // Loop the presentation
  loop: false,
  // Change the presentation direction to be RTL
  rtl: false,
  // Turns fragments on and off globally
  fragments: true,
  // Flags if the presentation is running in an embedded mode,
  // i.e. contained within a limited portion of the screen
  embedded: false,
  // Number of milliseconds between automatically proceeding to the
  // next slide, disabled when set to 0, this value can be overwritten
  // by using a data-autoslide attribute on your slides
  autoSlide: 0,
  // Stop auto-sliding after user input
  autoSlideStoppable: true,
  // Enable slide navigation via mouse wheel
  mouseWheel: false,
  // Hides the address bar on mobile devices
  hideAddressBar: true,
  // Opens links in an iframe preview overlay
  previewLinks: false,
  // Theme (e.g., beige, black, league, night, serif, simple, sky, solarized, white)
  // NOTE setting the theme in the config no longer works in reveal.js 3.x
  //theme: Reveal.getQueryHash().theme || 'white',
  // Transition style (e.g., none, fade, slide, convex, concave, zoom)
  transition: Reveal.getQueryHash().transition || 'linear',
  // Transition speed (e.g., default, fast, slow)
  transitionSpeed: 'default',
  // Transition style for full page slide backgrounds (e.g., none, fade, slide, convex, concave, zoom)
  backgroundTransition: 'fade',
  // Number of slides away from the current that are visible
  viewDistance: 3,
  // Parallax background image (e.g., "'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg'")
  parallaxBackgroundImage: '',
  // Parallax background size in CSS syntax (e.g., "2100px 900px")
  parallaxBackgroundSize: '',

  // The "normal" size of the presentation, aspect ratio will be preserved
  // when the presentation is scaled to fit different resolutions. Can be
  // specified using percentage units.
  width: 960,
  height: 700,

  // Factor of the display size that should remain empty around the content
  margin: 0.1,

  // Bounds for smallest/largest possible scale to apply to content
  minScale: 0.2,
  maxScale: 10.0,

  // Optional libraries used to extend on reveal.js
  dependencies: [
      { src: 'reveal.js-3.6.0/lib/js/classList.js', condition: function() { return !document.body.classList; } },
      { src: 'reveal.js-3.6.0/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
      { src: 'reveal.js-3.6.0/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
      
      { src: 'reveal.js-3.6.0/plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
      { src: 'reveal.js-3.6.0/plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }
  ]
});</script></body></html>